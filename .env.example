# Environment variable template for ai-chat-light
#
# Set the Ollama server address accessible from inside the container or your dev environment.
# Example: http://host.docker.internal:11434 (for Docker Desktop on Mac/Windows)
# Example: http://ollama:11434 (if using Docker Compose with a service named 'ollama')
# Example: http://localhost:11434 (for local development)

OLLAMA_HOST=http://host.docker.internal:11434
